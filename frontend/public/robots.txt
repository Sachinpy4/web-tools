# Web Tools - Robots.txt Configuration
# This file controls how search engines crawl and index your site

# Allow all search engines to crawl public content
User-agent: *

# DISALLOW: Admin, backend, and private areas
Disallow: /dashboard/
Disallow: /settings/
Disallow: /login
Disallow: /debug
Disallow: /api/

# DISALLOW: Old URLs that cause 404 errors
Disallow: /download/
Disallow: /Web

# DISALLOW: Sensitive files only (not CSS/JS - Google needs them!)
Disallow: /*.log$
Disallow: /*.env$
Disallow: /*.sql$
Disallow: /*.db$
Disallow: /*.bak$
Disallow: /*.config$
Disallow: /*.ini$

# Allow CSS and JS for proper rendering
# Allow: /*.css$
# Allow: /*.js$

# DISALLOW: Font files and source maps (not needed for indexing)
Disallow: /*.woff$
Disallow: /*.woff2$
Disallow: /*.ttf$
Disallow: /*.eot$
Disallow: /*.map$

# DISALLOW: Search and filter parameters to avoid duplicate content
# (Use rel="canonical" on these pages instead)
Disallow: /*?*search=*
Disallow: /*?*filter=*
Disallow: /*?*sort=*
Disallow: /*?*category=*
Disallow: /*?*tag=*

# Allow pagination for proper indexing
# Allow: /*?page=*



# SITEMAP: Point to sitemap location
Sitemap: https://toolscandy.com/sitemap.xml
# SPECIFIC RULES FOR MAJOR SEARCH ENGINES







